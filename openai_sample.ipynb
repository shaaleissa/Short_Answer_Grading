{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./.conda/lib/python3.10/site-packages (0.28.0)\n",
      "Collecting openai\n",
      "  Using cached openai-1.3.3-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in ./.conda/lib/python3.10/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.conda/lib/python3.10/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.conda/lib/python3.10/site-packages (from openai) (0.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.conda/lib/python3.10/site-packages (from openai) (2.5.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.conda/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in ./.conda/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.conda/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.conda/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in ./.conda/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
      "Requirement already satisfied: certifi in ./.conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore in ./.conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in ./.conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.conda/lib/python3.10/site-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Using cached openai-1.3.3-py3-none-any.whl (220 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.0\n",
      "    Uninstalling openai-0.28.0:\n",
      "      Successfully uninstalled openai-0.28.0\n",
      "Successfully installed openai-1.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been split and converted to JSONL format for chat-based model training.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "# Load your dataset\n",
    "csv_file = 'dataset_with_grades.csv'\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train, validation = train_test_split(data, test_size=0.2)\n",
    "\n",
    "def convert_to_chat_jsonl(df, filename):\n",
    "    \"\"\"\n",
    "    Converts a DataFrame to a JSONL file suitable for training with GPT-3.5-turbo in chat format.\n",
    "    :param df: DataFrame to convert.\n",
    "    :param filename: Output filename for the JSONL file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as file:\n",
    "        for _, row in df.iterrows():\n",
    "            # Construct a chat-like interaction\n",
    "            chat_interaction = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a tutor assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"What is the answer to this question: {row['Question']}\"},\n",
    "                    {\"role\": \"assistant\", \"content\": f\"The answer is {row['Instructor Answer']}.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"My answer is: {row['Student Answer']}\"},\n",
    "                    {\"role\": \"assistant\", \"content\": f\"Your answer is graded as {row['grade']}.\"}\n",
    "                ]\n",
    "            }\n",
    "            file.write(json.dumps(chat_interaction) + '\\n')\n",
    "\n",
    "# Convert and save the training and validation sets\n",
    "convert_to_chat_jsonl(train, 'Dataset/training_data.jsonl')\n",
    "convert_to_chat_jsonl(validation, 'Dataset/validation_data.jsonl')\n",
    "\n",
    "print(\"Data has been split and converted to JSONL format for chat-based model training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[FileObject](data=[FileObject(id='file-RvjvE1oiYaANy9au5pbpcRPQ', bytes=277191, created_at=1700397538, filename='validation_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-OeIFmrX4KtV5K4PtWTlIZ5Rn', bytes=1090630, created_at=1700397530, filename='training_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-FK3qpZn4QqQtBZP1PONUj0lT', bytes=212723, created_at=1700397243, filename='validation_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-AFWq4D3oymYGlEvdnxLkOQ4M', bytes=852290, created_at=1700397241, filename='training_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-AZ6qMdy5E6olkelNbNtDD98R', bytes=134419, created_at=1700396867, filename='validation_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-TCZUo4cJFN6ZMXNIcFXudDiJ', bytes=522219, created_at=1700396865, filename='training_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-xaTmnroQ0yaLlixQBhfWfREt', bytes=129243, created_at=1700396735, filename='validation_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None), FileObject(id='file-WA7Dm9zqPg34Pv1jaedt6O2i', bytes=527395, created_at=1700396734, filename='training_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)], object='list', has_more=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key='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')\n",
    "\n",
    "client.files.create(\n",
    "  file=open(\"Dataset/training_data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "client.files.create(\n",
    "  file=open(\"Dataset/validation_data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "client.files.list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-OeIFmrX4KtV5K4PtWTlIZ5Rn\", \n",
    "  validation_file=\"file-RvjvE1oiYaANy9au5pbpcRPQ\",\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  hyperparameters={\n",
    "    \"n_epochs\":2\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-dUy56trxMPdEGPYA9dQQPgOu', created_at=1700473936, error=None, fine_tuned_model='ft:gpt-3.5-turbo-0613:personal::8MwNH76d', finished_at=1700478299, hyperparameters=Hyperparameters(n_epochs=2, batch_size=2, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-ieFUJiLeKm8n3y0xVpV14355', result_files=['file-RkSJw36lVVpq6SYlSE1rFjpQ'], status='succeeded', trained_tokens=402086, training_file='file-OeIFmrX4KtV5K4PtWTlIZ5Rn', validation_file='file-RvjvE1oiYaANy9au5pbpcRPQ')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(\"ftjob-dUy56trxMPdEGPYA9dQQPgOu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Your answer is graded as 4.0.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0613:personal::8MwNH76d\",\n",
    "  messages= [\n",
    "    {\"role\": \"system\", \"content\": \"You are a tutor assistant.\"}, \n",
    "    {\"role\": \"user\", \"content\": \"What is the answer to this question: What is a tree?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"A tree is a hierarchical data structure defined as a collection of nodes. Nodes represent value and nodes are connected by edges. A tree has the following properties: The tree has one node called root. The tree originates from this, and hence it does not have any parent.\"}, \n",
    "    {\"role\": \"user\", \"content\": \"My answer is: A data structure\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
